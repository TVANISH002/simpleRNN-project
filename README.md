# simpleRNN-project

# ğŸ¬ IMDB Sentiment Analysis using Simple RNN

## ğŸ“Œ Project Overview

This project implements an **end-to-end Deep Learning sentiment analysis system** using a **Simple Recurrent Neural Network (SimpleRNN)** on the IMDB movie reviews dataset.
The primary goal is to understand how basic RNN architectures handle sequential text data and to analyze their strengths and limitations in real-world NLP tasks.

---

## ğŸ¯ Objective

* Build a complete NLP pipeline: **data loading â†’ preprocessing â†’ model training â†’ inference**
* Use **SimpleRNN** intentionally (not LSTM/GRU) for educational purposes
* Observe how SimpleRNN behaves on **positive vs negative sentiment**
* Deploy the trained model for real-time predictions using **Streamlit**

---

## ğŸ“‚ Project Structure

```
IMDB-Sentiment-Analysis/
â”‚
â”œâ”€â”€ app.py                  # Streamlit application
â”œâ”€â”€ simple_rnn_imdb.keras   # Trained SimpleRNN model
â”œâ”€â”€ requirements.txt        # Project dependencies
â”œâ”€â”€ README.md               # Project documentation
```

---

## ğŸ“Š Dataset

* **Dataset**: IMDB Movie Reviews (Keras built-in dataset)
* **Total samples**: 50,000 reviews

  * 25,000 training
  * 25,000 testing
* **Task**: Binary sentiment classification

  * `1` â†’ Positive
  * `0` â†’ Negative
* **Vocabulary size**: Top 10,000 most frequent words

---

## ğŸ§  Model Architecture (SimpleRNN)

```text
Embedding Layer (128 dimensions)
â†“
SimpleRNN (128 units, tanh activation)
â†“
Dropout (0.5)
â†“
Dense (Sigmoid)
```

### Why SimpleRNN?

The model deliberately uses **SimpleRNN** to:

* Understand basic sequence modeling
* Highlight vanishing gradient issues
* Compare against more advanced RNN variants in future work

---

## âš™ï¸ Training Details

* **Loss function**: Binary Crossentropy
* **Optimizer**: Adam (learning rate = 0.0003)
* **Batch size**: 32
* **Sequence length**: 100 tokens
* **EarlyStopping**:

  * Monitored on validation accuracy
  * Prevents overfitting
  * Restores best model weights

---

## âœ… Observed Strengths

The SimpleRNN model performs **well on positive sentiment**, especially when reviews contain strong positive keywords.

### Examples:

```
"Absolutely loved it" â†’ Positive (0.986)
"ğŸ‘ŒğŸ‘ŒğŸ‘Œ masterpiece" â†’ Positive (0.990)
"This movie was fantastic" â†’ Positive (0.908)
```

This indicates the model successfully learns **short-term word-level sentiment patterns**.

---

## âš ï¸ Observed Limitations

The model **struggles with negative sentiment**, particularly in cases involving:

* Negation (e.g., *"not good", "doesn't look nice"*)
* Strong negative expressions
* Slang and informal language
* Sarcasm or contextual meaning

### Examples:

```
"This movie is bad and it doesn't look nice" â†’ Positive (0.908)
"Worst film ever!!!" â†’ Positive (0.709)
```

---

## ğŸ” Technical Explanation of Limitations

SimpleRNN uses a **single hidden state**, which makes it difficult to:

* Retain long-term dependencies
* Handle negation effectively
* Capture sentence-level semantics

As sequences grow longer, earlier information fades due to the **vanishing gradient problem**, causing the model to rely more on isolated word presence than full contextual meaning.

This behavior is **expected and well-documented** in NLP research.

---

## ğŸ“ Educational Value

This project serves as a **learning-focused implementation** that:

* Demonstrates the full NLP deep learning workflow
* Highlights architectural limitations of SimpleRNN
* Provides a strong baseline for comparison with LSTM/GRU models

---

## ğŸš€ Future Improvements

Potential enhancements include:

* Replacing SimpleRNN with **LSTM or GRU**
* Using **Bidirectional RNNs**
* Adding **pretrained embeddings** (GloVe, Word2Vec)
* Preserving punctuation and emojis for richer sentiment cues
* Performing threshold calibration for class imbalance

---

## ğŸ§ª Deployment

The model is deployed using **Streamlit**, allowing users to input any movie review and receive:

* Sentiment classification (Positive / Negative)
* Prediction confidence score

---

## ğŸ“Œ Conclusion

This project successfully demonstrates an end-to-end sentiment analysis system using SimpleRNN. While the model performs reliably for positive sentiment detection, its difficulty in handling negative and context-dependent sentiment highlights the inherent limitations of basic RNN architectures. These findings reinforce the motivation for using more advanced recurrent models in real-world NLP applications.

---

## ğŸ‘¤ Author

**Anish Tirumala Venkata**
M.S. in Computer Science
University of Florida

